---
title: "Course 8 Project"
output: html_document
date: "2022-09-08"
---

# Machine Learning Final Project

```{r, echo =FALSE}
options(repos = list(CRAN="http://cran.rstudio.com/"))
install.packages("tidyverse")
install.packages("caret")
install.packages("randomForest")
install.packages("corrplot")
install.packages("rattle")
library(tidyverse)
library(caret)
library(randomForest)
library(corrplot)
library(rattle)
```

## Summary

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement -- a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants.

## Inputting and Cleaning Data

```{r, echo = TRUE}
training_raw <- read_csv("/Users/isabellademo/Downloads/pml-training.csv")
training_raw <- training_raw[, -c(1)]

testing_raw <- read_csv("/Users/isabellademo/Downloads/pml-testing.csv")
testing_raw <- testing_raw[, -c(1)]

valid <- read_csv("/Users/isabellademo/Downloads/pml-testing.csv")
```

### Cleaning out the missing values

```{r, echo = TRUE}
valid_in <- valid[, colSums(is.na(valid)) == 0]
train_in <- training_raw[, colSums(is.na(training_raw)) == 0]
test_in <- testing_raw[, colSums(is.na(testing_raw)) == 0]
```

Take out the irrelevant variables:

```{r, echo = TRUE}
train_in <- train_in[,-c(1:6)]
test_in <- test_in[,-c(1:6)]
```

### Creating Training and Test sets

```{r, echo = TRUE}
set.seed(1234)
inTrain <- createDataPartition(train_in$classe, p = 0.7, list = FALSE)
training <- train_in[inTrain, ]
testing <- train_in[-inTrain, ]
dim(training)
```

### Exploratory Correlation Plot

```{r, echo = TRUE}
cor_mat <- cor(training[, -53])
corrplot(cor_mat, order = "FPC", method = "color", type = "lower", 
         tl.cex = 0.8, tl.col = rgb(0, 0, 0),mar = c(1, 1, 1, 1))
```

Looking for highly correlated variables:

```{r, echo = TRUE}
high_cor = findCorrelation(cor_mat, cutoff = 0.75)
names(training)[high_cor]
```

## Model Testing

Testing three different models:\
1. Decision Trees\
2. Random Forests\
3. Generalized Boosted Model

Create the "fitControl" variable for cross-validation:

```{r, echo = TRUE}
fitControl <- trainControl(method="cv", number = 3)
```

### Decision Tree Model

```{r, echo = TRUE}
modFit <- train(classe~., method = "rpart", data = training, trControl = fitControl)
fancyRpartPlot(modFit$finalModel)
```

Using confusionMatrix to find accuracy via testing data:

```{r, echo = TRUE}
rpart_predict <- predict(modFit,newdata = testing)
rpart_matrix <- confusionMatrix(rpart_predict, as.factor(testing$classe))
print(rpart_matrix)
```

The accuracy is 0.49 and the out-of-sample error is around 0.51. This is a high out-of-sample error.

### Random Forest Model

```{r, echo = TRUE}
rf_model <- train(classe~., data= training, method="rf", trControl=fitControl, verbose=FALSE)
plot(rf_model,main="Random Forest Model Accuracy")
```

Using confusionMatrix to find accuracy via testing data:

```{r, echo = TRUE}
rf_predict <- predict(rf_model, newdata = testing)
rf_matrix <- confusionMatrix(rf_predict, as.factor(testing$classe))
print(rf_matrix)
```

The accuracy in this model is 0.99 and the out-of-sample error is 0.01 which is significant.

### GBM Model

```{r, echo = TRUE}
gbm_model <- train(classe~., data= training, method="gbm", trControl=fitControl, verbose=FALSE)
plot(gbm_model)
```

Using confusionMatrix to find accuracy via testing data:

```{r, echo = TRUE}
gbm_predict <- predict(gbm_model, newdata = testing)
gbm_matrix <- confusionMatrix(gbm_predict, as.factor(testing$classe))
print(gbm_matrix)
```

The accuracy of the GBM model is around 0.97 and the out-of-sample error is around 0.03.

## Best Model and Conclusions

The Random Forest model has the best accuracy and lowest out-of-sample error. We will now take the random forest model and apply it to the validation data.

```{r, echo = TRUE}
final_results <- predict(rf_model, newdata = valid_in)
print(final_results)
```

The results are the predicted classe outcomes for the next 20 numbers.
